{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-30T03:39:36.930683Z",
     "start_time": "2026-01-30T03:28:12.837383Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sympy import false\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "from dlordinal.losses import TriangularCrossEntropyLoss\n",
    "from dlordinal.metrics import amae\n",
    "\n",
    "# --- 1. 核心参数配置 ---\n",
    "DATA_DIR = 'datasets_split'\n",
    "NUM_CLASSES = 4        # 类别: 1, 2, 3, 4\n",
    "BATCH_SIZE = 32        #核显所以小一点\n",
    "NUM_EPOCHS = 20        #同上\n",
    "LEARNING_RATE = 0.001\n",
    "DEVICE = torch.device( \"cpu\")\n",
    "\n",
    "def main():\n",
    "    print(f\"当前运行设备: {DEVICE}\")\n",
    "\n",
    "    # --- 2. 数据预处理 ---\n",
    "    # 已经把图切成 224x224 了，所以这里是转 Tensor 和 归一化\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    # --- 3. 加载数据集 ---\n",
    "    image_datasets = {\n",
    "        x: datasets.ImageFolder(os.path.join(DATA_DIR, x), data_transforms[x])\n",
    "        for x in ['train', 'val']\n",
    "    }\n",
    "\n",
    "    # 封装 DataLoader\n",
    "    dataloaders = {\n",
    "        x: DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=(x=='train'), num_workers=0)\n",
    "        for x in ['train', 'val']\n",
    "    }\n",
    "\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "    print(f\"样本数量: 训练集 {dataset_sizes['train']} | 验证集 {dataset_sizes['val']}\")\n",
    "\n",
    "    # --- 4. 搭建模型  ---\n",
    "    model = models.resnet18(weights=None)\n",
    "\n",
    "    # 修改全连接层\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, NUM_CLASSES)\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    # --- 5. 定义有序分类 Loss ---\n",
    "    # 替换为dlordinal中的 Triangular Loss\n",
    "    # alpha 参数控制分布的尖锐程度，1.0 是标准三角形\n",
    "    criterion = TriangularCrossEntropyLoss(num_classes=NUM_CLASSES)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    # 学习率调整策略: 每 7 轮衰减一次\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "    # --- 6. 训练循环 ---\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_mae = float(10000000) # 我们的目标是让 MAE 越小越好,设置一个很大的初值\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f'\\nEpoch {epoch+1}/{NUM_EPOCHS}')\n",
    "        print('-' * 20)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # 用于计算整个 Epoch 的指标\n",
    "            epoch_probs = []\n",
    "            epoch_targets = []\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels) # dlordinal 会自动处理软标签\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # 收集预测概率 (为了算 MAE，必须先做 Softmax)\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                epoch_probs.append(probs.detach().cpu().numpy())\n",
    "                epoch_targets.append(labels.detach().cpu().numpy())\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            # 计算平均 Loss\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "\n",
    "            # 拼接所有 Batch 的结果\n",
    "            all_probs = np.concatenate(epoch_probs)\n",
    "            all_targets = np.concatenate(epoch_targets)\n",
    "\n",
    "            # --- 指标计算 ---\n",
    "            # 1. 常规准确率 (Accuracy)\n",
    "            preds = np.argmax(all_probs, axis=1)\n",
    "            acc = np.mean(preds == all_targets)\n",
    "\n",
    "            # 2. 有序度量 (MAE)\n",
    "            # 衡量平均偏离了几个等级\n",
    "            mae_score = amae(all_targets, all_probs)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} | Acc: {acc:.4f} | MAE: {mae_score:.4f}')\n",
    "\n",
    "            # --- 核心逻辑: 保存 MAE 最低的模型 ---\n",
    "            if phase == 'val' and mae_score < best_mae:\n",
    "                best_mae = mae_score\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                # 保存检查点\n",
    "                torch.save(model.state_dict(), 'best_ordinal_resnet18.pth')\n",
    "                print(f\" -> 发现更优模型 (MAE: {best_mae:.4f}) 已保存\")\n",
    "\n",
    "    print(f'\\n训练全部完成! 验证集最佳 MAE: {best_mae:.4f}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前运行设备: cpu\n",
      "样本数量: 训练集 482 | 验证集 121\n",
      "\n",
      "Epoch 1/20\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yunheishere\\AppData\\Local\\Temp\\ipykernel_8856\\2101149876.py:65: DeprecationWarning: Call to deprecated class TriangularCrossEntropyLoss. (Use TriangularLoss instead with CrossEntropyLoss as base_loss. Will be removed in 3.0.0.) -- Deprecated since version 2.4.0.\n",
      "  criterion = TriangularCrossEntropyLoss(num_classes=NUM_CLASSES)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6217 | Acc: 0.8672 | MAE: 0.1850\n",
      "val Loss: 35.2178 | Acc: 0.2479 | MAE: 1.1000\n",
      " -> 发现更优模型 (MAE: 1.1000) 已保存\n",
      "\n",
      "Epoch 2/20\n",
      "--------------------\n",
      "train Loss: 0.3355 | Acc: 0.9751 | MAE: 0.0310\n",
      "val Loss: 1.3887 | Acc: 0.6033 | MAE: 0.5417\n",
      " -> 发现更优模型 (MAE: 0.5417) 已保存\n",
      "\n",
      "Epoch 3/20\n",
      "--------------------\n",
      "train Loss: 0.3696 | Acc: 0.9585 | MAE: 0.0604\n",
      "val Loss: 0.9566 | Acc: 0.5702 | MAE: 0.4500\n",
      " -> 发现更优模型 (MAE: 0.4500) 已保存\n",
      "\n",
      "Epoch 4/20\n",
      "--------------------\n",
      "train Loss: 0.3182 | Acc: 0.9855 | MAE: 0.0188\n",
      "val Loss: 0.7425 | Acc: 0.7438 | MAE: 0.2578\n",
      " -> 发现更优模型 (MAE: 0.2578) 已保存\n",
      "\n",
      "Epoch 5/20\n",
      "--------------------\n",
      "train Loss: 0.3529 | Acc: 0.9772 | MAE: 0.0333\n",
      "val Loss: 2.0887 | Acc: 0.6281 | MAE: 0.8293\n",
      "\n",
      "Epoch 6/20\n",
      "--------------------\n",
      "train Loss: 0.3399 | Acc: 0.9772 | MAE: 0.0290\n",
      "val Loss: 0.4094 | Acc: 0.9669 | MAE: 0.0328\n",
      " -> 发现更优模型 (MAE: 0.0328) 已保存\n",
      "\n",
      "Epoch 7/20\n",
      "--------------------\n",
      "train Loss: 0.3543 | Acc: 0.9730 | MAE: 0.0397\n",
      "val Loss: 0.3968 | Acc: 0.9752 | MAE: 0.0247\n",
      " -> 发现更优模型 (MAE: 0.0247) 已保存\n",
      "\n",
      "Epoch 8/20\n",
      "--------------------\n",
      "train Loss: 0.2960 | Acc: 0.9917 | MAE: 0.0083\n",
      "val Loss: 0.2873 | Acc: 0.9835 | MAE: 0.0164\n",
      " -> 发现更优模型 (MAE: 0.0164) 已保存\n",
      "\n",
      "Epoch 9/20\n",
      "--------------------\n",
      "train Loss: 0.2889 | Acc: 0.9896 | MAE: 0.0103\n",
      "val Loss: 0.2862 | Acc: 0.9835 | MAE: 0.0164\n",
      "\n",
      "Epoch 10/20\n",
      "--------------------\n",
      "train Loss: 0.2958 | Acc: 0.9855 | MAE: 0.0167\n",
      "val Loss: 0.2817 | Acc: 0.9917 | MAE: 0.0083\n",
      " -> 发现更优模型 (MAE: 0.0083) 已保存\n",
      "\n",
      "Epoch 11/20\n",
      "--------------------\n",
      "train Loss: 0.2847 | Acc: 0.9917 | MAE: 0.0083\n",
      "val Loss: 0.2820 | Acc: 0.9835 | MAE: 0.0164\n",
      "\n",
      "Epoch 12/20\n",
      "--------------------\n",
      "train Loss: 0.2838 | Acc: 0.9896 | MAE: 0.0104\n",
      "val Loss: 0.2817 | Acc: 0.9835 | MAE: 0.0164\n",
      "\n",
      "Epoch 13/20\n",
      "--------------------\n",
      "train Loss: 0.2880 | Acc: 0.9876 | MAE: 0.0167\n",
      "val Loss: 0.2876 | Acc: 0.9835 | MAE: 0.0164\n",
      "\n",
      "Epoch 14/20\n",
      "--------------------\n",
      "train Loss: 0.2816 | Acc: 0.9917 | MAE: 0.0083\n",
      "val Loss: 0.2845 | Acc: 0.9835 | MAE: 0.0164\n",
      "\n",
      "Epoch 15/20\n",
      "--------------------\n",
      "train Loss: 0.2840 | Acc: 0.9917 | MAE: 0.0083\n",
      "val Loss: 0.2802 | Acc: 0.9835 | MAE: 0.0164\n",
      "\n",
      "Epoch 16/20\n",
      "--------------------\n",
      "train Loss: 0.2795 | Acc: 0.9917 | MAE: 0.0083\n",
      "val Loss: 0.2829 | Acc: 0.9835 | MAE: 0.0164\n",
      "\n",
      "Epoch 17/20\n",
      "--------------------\n",
      "train Loss: 0.2799 | Acc: 0.9917 | MAE: 0.0083\n",
      "val Loss: 0.2772 | Acc: 0.9835 | MAE: 0.0164\n",
      "\n",
      "Epoch 18/20\n",
      "--------------------\n",
      "train Loss: 0.2815 | Acc: 0.9876 | MAE: 0.0125\n",
      "val Loss: 0.2777 | Acc: 0.9835 | MAE: 0.0164\n",
      "\n",
      "Epoch 19/20\n",
      "--------------------\n",
      "train Loss: 0.2823 | Acc: 0.9917 | MAE: 0.0083\n",
      "val Loss: 0.2765 | Acc: 0.9835 | MAE: 0.0164\n",
      "\n",
      "Epoch 20/20\n",
      "--------------------\n",
      "train Loss: 0.2857 | Acc: 0.9917 | MAE: 0.0083\n",
      "val Loss: 0.2757 | Acc: 0.9835 | MAE: 0.0164\n",
      "\n",
      "训练全部完成! 验证集最佳 MAE: 0.0083\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T03:27:56.618593Z",
     "start_time": "2026-01-30T03:27:56.613094Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "228ab11829945eae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4d03e21edcccc1b9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
