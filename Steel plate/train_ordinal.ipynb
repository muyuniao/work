{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-02-01T11:10:40.864523Z"
    },
    "collapsed": true,
    "jupyter": {
     "is_executing": true,
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前运行设备: cpu\n",
      "样本数量: 训练集 31250 | 验证集 7814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\yunheishere\\AppData\\Local\\Temp\\ipykernel_52652\\1872233143.py:64: DeprecationWarning: Call to deprecated class TriangularCrossEntropyLoss. (Use TriangularLoss instead with CrossEntropyLoss as base_loss. Will be removed in 3.0.0.) -- Deprecated since version 2.4.0.\n",
      "  criterion = TriangularCrossEntropyLoss(num_classes=NUM_CLASSES)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "from dlordinal.losses import TriangularCrossEntropyLoss\n",
    "from dlordinal.metrics import amae\n",
    "\n",
    "# --- 1. 核心参数配置 ---\n",
    "DATA_DIR = 'datasets_split'\n",
    "NUM_CLASSES = 4        # 类别: 1, 2, 3, 4\n",
    "BATCH_SIZE = 32        #核显所以小一点\n",
    "NUM_EPOCHS = 20        #同上\n",
    "LEARNING_RATE = 0.001\n",
    "DEVICE = torch.device( \"cpu\")\n",
    "\n",
    "def main():\n",
    "    print(f\"当前运行设备: {DEVICE}\")\n",
    "\n",
    "    # --- 2. 数据预处理 ---\n",
    "    # 已经把图切成 224x224 了，所以这里是转 Tensor 和 归一化\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    # --- 3. 加载数据集 ---\n",
    "    image_datasets = {\n",
    "        x: datasets.ImageFolder(os.path.join(DATA_DIR, x), data_transforms[x])\n",
    "        for x in ['train', 'val']\n",
    "    }\n",
    "\n",
    "    # 封装 DataLoader\n",
    "    dataloaders = {\n",
    "        x: DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=(x=='train'), num_workers=0)\n",
    "        for x in ['train', 'val']\n",
    "    }\n",
    "\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "    print(f\"样本数量: 训练集 {dataset_sizes['train']} | 验证集 {dataset_sizes['val']}\")\n",
    "\n",
    "    # --- 4. 搭建模型  ---\n",
    "    model = models.resnet18(pretrained=True)\n",
    "\n",
    "    # 修改全连接层\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, NUM_CLASSES)\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    # --- 5. 定义有序分类 Loss ---\n",
    "    # 替换为dlordinal中的 Triangular Loss\n",
    "    # alpha 参数控制分布的尖锐程度，1.0 是标准三角形\n",
    "    criterion = TriangularCrossEntropyLoss(num_classes=NUM_CLASSES)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    # 学习率调整策略: 每 7 轮衰减一次\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "    # --- 6. 训练循环 ---\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_mae = float(10000000) # 我们的目标是让 MAE 越小越好,设置一个很大的初值\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f'\\nEpoch {epoch+1}/{NUM_EPOCHS}')\n",
    "        print('-' * 20)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # 用于计算整个 Epoch 的指标\n",
    "            epoch_probs = []\n",
    "            epoch_targets = []\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels) # dlordinal 会自动处理软标签\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # 收集预测概率 (为了算 MAE，必须先做 Softmax)\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                epoch_probs.append(probs.detach().cpu().numpy())\n",
    "                epoch_targets.append(labels.detach().cpu().numpy())\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            # 计算平均 Loss\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "\n",
    "            # 拼接所有 Batch 的结果\n",
    "            all_probs = np.concatenate(epoch_probs)\n",
    "            all_targets = np.concatenate(epoch_targets)\n",
    "\n",
    "            # --- 指标计算 ---\n",
    "            # 1. 常规准确率 (Accuracy)\n",
    "            preds = np.argmax(all_probs, axis=1)\n",
    "            acc = np.mean(preds == all_targets)\n",
    "\n",
    "            # 2. 有序指标 (MAE)\n",
    "            # 衡量平均偏离了几个等级\n",
    "            mae_score = amae(all_targets, all_probs)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} | Acc: {acc:.4f} | MAE: {mae_score:.4f}')\n",
    "\n",
    "            # --- 核心逻辑: 保存 MAE 最低的模型 ---\n",
    "            if phase == 'val' and mae_score < best_mae:\n",
    "                best_mae = mae_score\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                # 保存检查点\n",
    "                torch.save(model.state_dict(), 'best_ordinal_resnet18.pth')\n",
    "                print(f\" -> 发现更优模型 (MAE: {best_mae:.4f}) 已保存\")\n",
    "\n",
    "    print(f'\\n训练全部完成! 验证集最佳 MAE: {best_mae:.4f}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8254639e4971b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
