{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "from dlordinal.losses import TriangularCrossEntropyLoss\n",
    "from dlordinal.metrics import amae\n",
    "\n",
    "# --- 1. æ ¸å¿ƒå‚æ•°é…ç½® ---\n",
    "DATA_DIR = 'dataset_split'\n",
    "NUM_CLASSES = 4        # ç±»åˆ«: 1, 2, 3, 4 (ä»£ç å†…éƒ¨ä¼šæ˜ å°„ä¸º 0,1,2,3)\n",
    "BATCH_SIZE = 32        #\n",
    "NUM_EPOCHS = 20        #\n",
    "LEARNING_RATE = 0.001\n",
    "DEVICE = torch.device( \"cpu\")\n",
    "\n",
    "def main():\n",
    "    print(f\"å½“å‰è¿è¡Œè®¾å¤‡: {DEVICE}\")\n",
    "\n",
    "    # --- 2. æ•°æ®é¢„å¤„ç† ---\n",
    "    # å·²ç»æŠŠå›¾åˆ‡æˆ 224x224 äº†ï¼Œæ‰€ä»¥è¿™é‡Œæ˜¯è½¬ Tensor å’Œ å½’ä¸€åŒ–\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    # --- 3. åŠ è½½æ•°æ®é›† ---\n",
    "    image_datasets = {\n",
    "        x: datasets.ImageFolder(os.path.join(DATA_DIR, x), data_transforms[x])\n",
    "        for x in ['train', 'val']\n",
    "    }\n",
    "\n",
    "    # å°è£… DataLoader\n",
    "    dataloaders = {\n",
    "        x: DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=(x=='train'), num_workers=0)\n",
    "        for x in ['train', 'val']\n",
    "    }\n",
    "\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "    # æ‰“å°æ˜ å°„å…³ç³»ï¼Œä¸€å®šè¦æ£€æŸ¥ï¼\n",
    "    # ç†æƒ³è¾“å‡º: {'1': 0, '2': 1, '3': 2, '4': 3}\n",
    "    print(f\"ç±»åˆ«æ˜ å°„è¡¨ (æ–‡ä»¶å¤¹å -> Label): {image_datasets['train'].class_to_idx}\")\n",
    "    print(f\"æ ·æœ¬æ•°é‡: è®­ç»ƒé›† {dataset_sizes['train']} | éªŒè¯é›† {dataset_sizes['val']}\")\n",
    "\n",
    "    # --- 4. æ­å»ºæ¨¡å‹ (ResNet18 Backbone) ---\n",
    "    model = models.resnet18(pretrained=True)\n",
    "\n",
    "    # ä¿®æ”¹å…¨è¿æ¥å±‚\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, NUM_CLASSES)\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    # --- 5. å®šä¹‰æœ‰åºåˆ†ç±» Loss (å…³é”®) ---\n",
    "    # ä½¿ç”¨ Triangular Loss (è®ºæ–‡æ¨è)\n",
    "    # alpha å‚æ•°æ§åˆ¶åˆ†å¸ƒçš„å°–é”ç¨‹åº¦ï¼Œ1.0 æ˜¯æ ‡å‡†ä¸‰è§’å½¢\n",
    "    criterion = TriangularCrossEntropyLoss(num_classes=NUM_CLASSES, alpha=1.0)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    # å­¦ä¹ ç‡è°ƒæ•´ç­–ç•¥: æ¯ 7 è½®è¡°å‡ä¸€æ¬¡\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "    # --- 6. è®­ç»ƒå¾ªç¯ ---\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_mae = float('inf') # æˆ‘ä»¬çš„ç›®æ ‡æ˜¯è®© MAE è¶Šå°è¶Šå¥½\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f'\\nEpoch {epoch+1}/{NUM_EPOCHS}')\n",
    "        print('-' * 20)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # ç”¨äºè®¡ç®—æ•´ä¸ª Epoch çš„æŒ‡æ ‡\n",
    "            epoch_probs = []\n",
    "            epoch_targets = []\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels) # dlordinal ä¼šè‡ªåŠ¨å¤„ç†è½¯æ ‡ç­¾\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # æ”¶é›†é¢„æµ‹æ¦‚ç‡ (ä¸ºäº†ç®— MAEï¼Œå¿…é¡»å…ˆåš Softmax)\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                epoch_probs.append(probs.detach().cpu().numpy())\n",
    "                epoch_targets.append(labels.detach().cpu().numpy())\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            # è®¡ç®—å¹³å‡ Loss\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "\n",
    "            # æ‹¼æ¥æ‰€æœ‰ Batch çš„ç»“æœ\n",
    "            all_probs = np.concatenate(epoch_probs)\n",
    "            all_targets = np.concatenate(epoch_targets)\n",
    "\n",
    "            # --- æŒ‡æ ‡è®¡ç®— ---\n",
    "            # 1. å¸¸è§„å‡†ç¡®ç‡ (Accuracy)\n",
    "            preds = np.argmax(all_probs, axis=1)\n",
    "            acc = np.mean(preds == all_targets)\n",
    "\n",
    "            # 2. æœ‰åºæŒ‡æ ‡ (MAE)\n",
    "            # è¡¡é‡å¹³å‡åç¦»äº†å‡ ä¸ªç­‰çº§\n",
    "            mae_score = amae(all_targets, all_probs)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} | Acc: {acc:.4f} | MAE: {mae_score:.4f}')\n",
    "\n",
    "            # --- æ ¸å¿ƒé€»è¾‘: ä¿å­˜ MAE æœ€ä½çš„æ¨¡å‹ ---\n",
    "            if phase == 'val' and mae_score < best_mae:\n",
    "                best_mae = mae_score\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                # ä¿å­˜æ£€æŸ¥ç‚¹\n",
    "                torch.save(model.state_dict(), 'best_ordinal_resnet18.pth')\n",
    "                print(f\" -> ğŸŒŸ å‘ç°æ›´ä¼˜æ¨¡å‹ (MAE: {best_mae:.4f}) å·²ä¿å­˜\")\n",
    "\n",
    "    print(f'\\nè®­ç»ƒå…¨éƒ¨å®Œæˆ! éªŒè¯é›†æœ€ä½³ MAE: {best_mae:.4f}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
