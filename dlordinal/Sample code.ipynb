{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c378af62-0dbe-4ad6-bccc-d17ab7bc7587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already processed and verified\n",
      "Files already split and verified\n",
      "Files already downloaded and verified\n",
      "Files already processed and verified\n",
      "Files already split and verified\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m1.7190\u001b[0m       \u001b[32m0.3168\u001b[0m        \u001b[35m1.7735\u001b[0m  27.6544\n",
      "      2        \u001b[36m0.9176\u001b[0m       \u001b[32m0.3602\u001b[0m        1.7816  22.2978\n",
      "      3        \u001b[36m0.5885\u001b[0m       \u001b[32m0.5093\u001b[0m        \u001b[35m1.4999\u001b[0m  22.1870\n",
      "      4        \u001b[36m0.4544\u001b[0m       0.4658        1.9440  23.4645\n",
      "      5        \u001b[36m0.3989\u001b[0m       \u001b[32m0.5776\u001b[0m        \u001b[35m1.1674\u001b[0m  22.7371\n",
      "      6        \u001b[36m0.3826\u001b[0m       0.5776        1.1716  22.6531\n",
      "      7        \u001b[36m0.3633\u001b[0m       \u001b[32m0.5963\u001b[0m        \u001b[35m1.1281\u001b[0m  22.1734\n",
      "      8        \u001b[36m0.3565\u001b[0m       \u001b[32m0.6211\u001b[0m        \u001b[35m1.0612\u001b[0m  22.7198\n",
      "      9        \u001b[36m0.3518\u001b[0m       0.6149        \u001b[35m1.0575\u001b[0m  22.2039\n",
      "     10        \u001b[36m0.3492\u001b[0m       0.6025        \u001b[35m1.0387\u001b[0m  21.9576\n",
      "     11        \u001b[36m0.3476\u001b[0m       0.6211        1.0418  22.3816\n",
      "     12        \u001b[36m0.3464\u001b[0m       0.6211        \u001b[35m1.0222\u001b[0m  26.4979\n",
      "     13        \u001b[36m0.3458\u001b[0m       0.6149        \u001b[35m1.0121\u001b[0m  28.6784\n",
      "     14        \u001b[36m0.3453\u001b[0m       0.6211        1.0161  24.2921\n",
      "     15        \u001b[36m0.3449\u001b[0m       \u001b[32m0.6335\u001b[0m        1.0190  25.6208\n",
      "     16        \u001b[36m0.3447\u001b[0m       0.6211        1.0165  24.6198\n",
      "     17        \u001b[36m0.3445\u001b[0m       0.6335        1.0166  26.8039\n",
      "     18        \u001b[36m0.3444\u001b[0m       0.6335        1.0195  25.6668\n",
      "     19        \u001b[36m0.3443\u001b[0m       0.6335        1.0222  24.0668\n",
      "     20        \u001b[36m0.3442\u001b[0m       0.6335        1.0240  22.6624\n",
      "     21        \u001b[36m0.3441\u001b[0m       0.6335        1.0242  24.2208\n",
      "     22        \u001b[36m0.3441\u001b[0m       0.6335        1.0263  22.1857\n",
      "     23        \u001b[36m0.3440\u001b[0m       0.6335        1.0280  22.8744\n",
      "     24        \u001b[36m0.3440\u001b[0m       0.6335        1.0292  23.4356\n",
      "     25        \u001b[36m0.3439\u001b[0m       0.6335        1.0301  22.0860\n",
      "Test AMAE: 0.5201659451659452, Test MMAE: 0.7575757575757576\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dlordinal.datasets import FGNet\n",
    "from dlordinal.losses import TriangularLoss\n",
    "from dlordinal.metrics import amae, mmae\n",
    "from skorch import NeuralNetClassifier\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torchvision import models\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "\n",
    "# Download the FGNet dataset\n",
    "fgnet_train = FGNet(\n",
    "    root=\"./datasets\",\n",
    "    train=True,\n",
    "    #强制转换为 int64）\n",
    "    target_transform=lambda x: np.array(x, dtype=np.int64),\n",
    "    transform=Compose([ToTensor()]),\n",
    ")\n",
    "fgnet_test = FGNet(\n",
    "    root=\"./datasets\",\n",
    "    train=False,\n",
    "    #强制转换为 int64）\n",
    "    target_transform=lambda x: np.array(x, dtype=np.int64),\n",
    "    transform=Compose([ToTensor()]),\n",
    ")\n",
    "\n",
    "num_classes_fgnet = len(fgnet_train.classes)\n",
    "\n",
    "# Model\n",
    "model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes_fgnet)\n",
    "\n",
    "# Loss function\n",
    "loss_fn = TriangularLoss(base_loss=nn.CrossEntropyLoss(), num_classes=num_classes_fgnet)\n",
    "\n",
    "# Skorch estimator\n",
    "estimator = NeuralNetClassifier(\n",
    "    module=model,\n",
    "    criterion=loss_fn,\n",
    "    optimizer=Adam,\n",
    "    lr=1e-3,\n",
    "    max_epochs=25,\n",
    ")\n",
    "\n",
    "estimator.fit(X=fgnet_train, y=fgnet_train.targets)\n",
    "train_probs = estimator.predict_proba(fgnet_train)\n",
    "test_probs = estimator.predict_proba(fgnet_test)\n",
    "\n",
    "# Metrics\n",
    "amae_metric = amae(np.array(fgnet_test.targets), test_probs)\n",
    "mmae_metric = mmae(np.array(fgnet_test.targets), test_probs)\n",
    "print(f\"Test AMAE: {amae_metric}, Test MMAE: {mmae_metric}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
